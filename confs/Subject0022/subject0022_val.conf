general {
    output_dir = ./dump_results/Subject0022_val_output/
    device = cuda:0                         # for the main model
    device_dataset = cuda:0                 # for the character in case run out of memory
}

character{
    skeleton_dir =./meta_data/Subject0022/ddc.skeleton                      # skeleton file
    skinning_dir =./meta_data/Subject0022/ddc.skin                          # the skinning weights
    template_mesh_dir =./meta_data/Subject0022/ddc.obj                      # the template meshes 
    graph_dir = ./meta_data/Subject0022/ddc_graph.obj                       # the embedded graph, which is a lower res ones
    rest_pose_dir = ./meta_data/Subject0022/ddc.motion                      # the rest pose 
    blending_type = dqs                                                     # dqs / lbs
    deformation_type = embedded                                             # embedded / lbs 
    hand_mask_dir = ./meta_data/Subject0022/hand_segmentation.txt           # for Dynacap Dataset characters we comment out this entry ;D
    use_sparse = True                                                       # sparse link for the characters connectivity matrix
    compute_eg = False                                                      # whether to pose the "locally embedded defomred "                                           
    compute_delta = True                                                    # whether to pose the "locally embedded + per-vertex defomred"      
    compute_posed = False                                                   # whether to pose the "original template"     
}

# settings for the embedded deformation module
spatial_gcn { 
    dense_initializer_scale = 0.001
    feature_size1 = 16
    feature_size2 = 16
    use_batch_norm = 1
    fully_connected = 'nofull'
    ring_value = 2
    normalize = 1
    dense_inner_block = 0
    num_residual_blocks = 8
    input_size = 18
    output_size = 6
}

# settings for the per-vertex deformation module
delta_gcn { 
    dense_initializer_scale = 0.001
    feature_size1 = 16
    feature_size2 = 16
    use_batch_norm = 0
    fully_connected = 'nofull'
    ring_value = 3
    normalize = 1
    dense_inner_block = 1
    num_residual_blocks = 8
    input_size = 9
    output_size = 3
}

dataset {
    # dofs
    skeleton_angles = ./meta_data/Subject0022/skeletoolToGTPose/poseAngles.motion
    # rotation, and translation normalized dof; of (n, n-1, n-2 th frame) w.r.t the nth frame :D
    skeleton_angles_rotation_normalized = ./meta_data/Subject0022/skeletoolToGTPose/poseAnglesRotationNormalized.motion
    # converted from the original calibration file to the gaussian compatible ones
    camera_json_dir = ./meta_data/Subject0022/cameras.json
    
    camera_num = 114
    # the cameras adotped for dumping imgs
    val_camera = [40]

    img_width = 1285
    img_height = 940
    # depends on the unet that u use, the releaseed model will use 256 to balance qulity and runtime
    barycentric_tex_size = 256

    val_frame_start = 110
    val_frame_end = 1000
    # dump every ....
    val_sample_interval = 10

    is_white_background = True
}

train {
    
    load_eg_checkpoints = False
    eg_checkpoint_dir = False

    load_delta_checkpoints = True
    
    # point to the deformable character checkpoint
    delta_checkpoint_dir = ./checkpoints/Subject0022/deformable_character_checkpoint.pth

    # point to the gaussians
    gaussian_checkpoint_dir = ./checkpoints/Subject0022/gaussian_checkpoints.tar
}


model {

    extra_settings {
        # should be fine even if we remove it
        real_global_translation_dir = ./meta_data/Subject0022/real_translation.txt
    }

    gaussian{
        sh_degree = 3
    }
}